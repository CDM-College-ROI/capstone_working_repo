{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling / Cluster Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "# default pandas decimal number display format\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Wrangling\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.feature_selection import SelectKBest, RFE, f_regression, SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr, kruskal\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "import csv\n",
    "import acquire\n",
    "import prepare\n",
    "import explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = acquire.get_bach_df()\n",
    "df = prepare.clean_college_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaned_df = prepare.clean_step1(df)\n",
    "new_df = prepare.avg_net_price(cleaned_df)\n",
    "new_df['major_category'] = new_df.major_name.apply(prepare.categorize_major)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure you have `2017_2018_2019_earning_by_major.csv` within working folder\n",
    "\n",
    "new_df = prepare.earnings_merge(new_df)\n",
    "df = prepare.create_roi_cols(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# income brackets\n",
    "\n",
    "income_0_30000 = [\n",
    "'other_fam_income_0_30000',\n",
    " 'private_fam_income_0_30000',\n",
    " 'program_fam_income_0_30000',\n",
    " 'pub_fam_income_0_30000']\n",
    "\n",
    "income_30001_48000 = [\n",
    " 'other_fam_income_30001_48000',\n",
    " 'private_fam_income_30001_48000',\n",
    " 'program_fam_income_30001_48000',\n",
    " 'pub_fam_income_30001_48000']\n",
    "\n",
    "income_48001_75000 = [\n",
    "'other_fam_income_48001_75000',\n",
    "'private_fam_income_48001_75000',\n",
    "'program_fam_income_48001_75000',\n",
    "'pub_fam_income_48001_75000']\n",
    "\n",
    "income_75001_110000 = [\n",
    "'other_fam_income_75001_110000',\n",
    "'private_fam_income_75001_110000',\n",
    "'program_fam_income_75001_110000',\n",
    "'pub_fam_income_75001_110000']\n",
    "\n",
    "income_over_110000 = [\n",
    "'other_fam_income_over_110000',\n",
    "'private_fam_income_over_110000',\n",
    "'program_fam_income_over_110000',\n",
    "'pub_fam_income_over_110000']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = prepare.get_fam_income_col(df, income_0_30000, \"fam_income_0_30000\")\n",
    "df = prepare.get_fam_income_col(df, income_30001_48000, \"fam_income_30001_48000\")\n",
    "df = prepare.get_fam_income_col(df, income_48001_75000, \"fam_income_48001_75000\")\n",
    "df = prepare.get_fam_income_col(df, income_75001_110000, \"fam_income_75001_110000\")\n",
    "df = prepare.get_fam_income_col(df, income_over_110000, \"fam_income_over_110000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling split df from Google Drive\n",
    "train = pd.read_csv('train_imputed.csv')\n",
    "validate = pd.read_csv('validate_imputed.csv')\n",
    "test = pd.read_csv('test_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "Features to scale:\n",
    "\n",
    "avg_sat_admitted\n",
    "avg_faculty_salary\n",
    "med_debt_pell_students\n",
    "med_debt_non_pell\n",
    "median_debt_completed\n",
    "fam_income_0_30000\n",
    "fam_income_30001_48000\n",
    "fam_income_48001_75000\n",
    "fam_income_75001_110000\n",
    "fam_income_over_110000\n",
    "avg_net_price\n",
    "2017\n",
    "2018\n",
    "2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train, validate, test):\n",
    "    \n",
    "    scale_columns = ['avg_sat_admitted', 'ACT_score_mid', 'title_IV_student_number', 'avg_faculty_salary', 'med_debt_pell_students', 'median_debt_non_pell', 'median_debt_completed', 'fam_income_0_30000', 'fam_income_30001_48000', 'fam_income_48001_75000', 'fam_income_75001_110000', 'fam_income_over_110000', 'avg_net_price', '2017', '2018', '2019']\n",
    "    \n",
    "    train_scaled = train.copy()\n",
    "    validate_scaled = validate.copy()\n",
    "    test_scaled = test.copy()\n",
    "    \n",
    "    mms = MinMaxScaler()\n",
    "    \n",
    "    mms.fit(train[scale_columns])\n",
    "    \n",
    "    train_scaled[scale_columns] = mms.transform(train[scale_columns])\n",
    "    validate_scaled[scale_columns] = mms.transform(validate[scale_columns])\n",
    "    test_scaled[scale_columns] = mms.transform(test[scale_columns])\n",
    "    \n",
    "    return train_scaled, validate_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling our model.py; Assigning df variables to our called function, `scale_data`\n",
    "train_scaled, validate_scaled, test_scaled = scale_data(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k(x_train_scaled, cluster_vars, k_range):\n",
    "    sse = []\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "\n",
    "        # X[0] is our X_train dataframe..the first dataframe in the list of dataframes stored in X. \n",
    "        kmeans.fit(x_train_scaled[cluster_vars])\n",
    "\n",
    "        # inertia: Sum of squared distances of samples to their closest cluster center.\n",
    "        sse.append(kmeans.inertia_) \n",
    "\n",
    "    # compute the difference from one k to the next\n",
    "    delta = [round(sse[i] - sse[i+1],0) for i in range(len(sse)-1)]\n",
    "\n",
    "    # compute the percent difference from one k to the next\n",
    "    pct_delta = [round(((sse[i] - sse[i+1])/sse[i])*100, 1) for i in range(len(sse)-1)]\n",
    "\n",
    "    # create a dataframe with all of our metrics to compare them across values of k: SSE, delta, pct_delta\n",
    "    k_comparisons_df = pd.DataFrame(dict(k=k_range[0:-1], \n",
    "                             sse=sse[0:-1], \n",
    "                             delta=delta, \n",
    "                             pct_delta=pct_delta))\n",
    "\n",
    "    # plot k with inertia\n",
    "    plt.plot(k_comparisons_df.k, k_comparisons_df.sse, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('SSE')\n",
    "    plt.title('The Elbow Method to find the optimal k\\nFor which k values do we see large decreases in SSE?')\n",
    "    plt.show()\n",
    "\n",
    "    # plot k with pct_delta\n",
    "    plt.plot(k_comparisons_df.k, k_comparisons_df.pct_delta, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Percent Change')\n",
    "    plt.title('For which k values are we seeing increased changes (%) in SSE?')\n",
    "    plt.show()\n",
    "\n",
    "    # plot k with delta\n",
    "    plt.plot(k_comparisons_df.k, k_comparisons_df.delta, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Absolute Change in SSE')\n",
    "    plt.title('For which k values are we seeing increased changes (absolute) in SSE?')\n",
    "    plt.show()\n",
    "\n",
    "    return k_comparisons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 1: `major_category`, `admission_rate`, `avg_sat_admitted`, `median_debt_completed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables I will cluster on. \n",
    "cluster_vars = ['admission_rate', 'avg_sat_admitted', 'median_debt_completed']\n",
    "cluster_name = 'Admission with Debt'\n",
    "k_range = range(2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_k(train_scaled, cluster_vars, k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create kmean object\n",
    "kmeans = KMeans(n_clusters=5, random_state = 123)\n",
    "\n",
    "# fit to train and assign cluster ids to observations\n",
    "kmeans.fit(train_scaled[cluster_vars])\n",
    "\n",
    "cluster1 = kmeans.predict(train_scaled[cluster_vars])\n",
    "\n",
    "cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled['admission_to_debt_cluster'] = cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(train_scaled['admission_to_debt_cluster'], prefix= 'area', drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the cluster\n",
    "#sns.scatterplot(data=train_scaled['area_cluster'], y = 'longitude', x = 'logerror', hue= 'area_cluster')\n",
    "plt.show()\n",
    "sns.barplot(data=train_scaled, x='admission_to_debt_cluster', y='roi_5yr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 2: `region_ipeds`, `avg_faculty_salary`, `avg_sat_admitted`, `admission_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables I will cluster on. \n",
    "cluster_vars_2 = ['region_ipeds', 'avg_sat_admitted', 'avg_faculty_salary', 'admission_rate']\n",
    "cluster_name_2 = 'Admission by Region'\n",
    "k_range = range(2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_k(train_scaled, cluster_vars_2, k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create kmean object\n",
    "kmeans = KMeans(n_clusters=4, random_state = 123)\n",
    "\n",
    "# fit to train and assign cluster ids to observations\n",
    "kmeans.fit(train_scaled[cluster_vars_2])\n",
    "\n",
    "cluster2 = kmeans.predict(train_scaled[cluster_vars_2])\n",
    "\n",
    "cluster2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled['admission_by_region_cluster'] = cluster2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(train_scaled['admission_by_region_cluster'], prefix= 'region', drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the cluster\n",
    "#sns.scatterplot(data=train_scaled['area_cluster'], y = 'longitude', x = 'logerror', hue= 'area_cluster')\n",
    "plt.show()\n",
    "sns.barplot(data=train_scaled, x='admission_by_region_cluster', y='roi_5yr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 3: `fam_income_0_30000`, `fam_income_30001_48000`, `fam_income_48001_75000`, `fam_income_75001_110000`, `fam_income_over_110000`, `admission_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables I will cluster on. \n",
    "cluster_vars_3 = ['fam_income_0_30000', 'fam_income_30001_48000', 'fam_income_48001_75000', 'fam_income_75001_110000', 'fam_income_over_110000', 'admission_rate']\n",
    "cluster_name_3 = 'Admission by Family Income'\n",
    "k_range = range(2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_k(train_scaled, cluster_vars_3, k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create kmean object\n",
    "kmeans = KMeans(n_clusters=4, random_state = 123)\n",
    "\n",
    "# fit to train and assign cluster ids to observations\n",
    "kmeans.fit(train_scaled[cluster_vars_3])\n",
    "\n",
    "cluster3 = kmeans.predict(train_scaled[cluster_vars_3])\n",
    "\n",
    "cluster3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled['admission_by_fam_income'] = cluster3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(train_scaled['admission_by_fam_income'], prefix= 'income', drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the cluster\n",
    "#sns.scatterplot(data=train_scaled['area_cluster'], y = 'longitude', x = 'logerror', hue= 'area_cluster')\n",
    "plt.show()\n",
    "sns.barplot(data=train_scaled, x='admission_by_fam_income', y='roi_5yr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 4: \n",
    "`admission_rate`, `avg_sat_admitted`, `avg_faculty_salary`, `med_debt_pell_students`, `median_debt_non_pell`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables I will cluster on. \n",
    "cluster_vars_4 = ['admission_rate', 'avg_sat_admitted', 'avg_faculty_salary', 'med_debt_pell_students', 'median_debt_non_pell']\n",
    "cluster_name_4 = 'Admission, SAT score, fac_salary, by Debt Pell and non-Pell'\n",
    "k_range = range(2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_k(train_scaled, cluster_vars_4, k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create kmean object\n",
    "kmeans = KMeans(n_clusters=4, random_state = 123)\n",
    "\n",
    "# fit to train and assign cluster ids to observations\n",
    "kmeans.fit(train_scaled[cluster_vars_4])\n",
    "\n",
    "cluster4 = kmeans.predict(train_scaled[cluster_vars_4])\n",
    "\n",
    "cluster4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled['admission_by_region_debt'] = cluster4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(train_scaled['admission_by_region_debt'], prefix= 'region_debt', drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the cluster\n",
    "#sns.scatterplot(data=train_scaled['area_cluster'], y = 'longitude', x = 'logerror', hue= 'area_cluster')\n",
    "plt.show()\n",
    "sns.barplot(data=train_scaled, x='admission_by_region_debt', y='roi_5yr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 5: `major_category`, `admission_rate`, `avg_sat_admitted`, `median_debt_completed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables I will cluster on. \n",
    "cluster_vars_5 = ['admission_rate', 'avg_sat_admitted', 'median_debt_completed']\n",
    "cluster_name_5 = 'Admission with Debt'\n",
    "k_range = range(2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_k(train_scaled, cluster_vars, k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create kmean object\n",
    "kmeans = KMeans(n_clusters=5, random_state = 123)\n",
    "\n",
    "# fit to train and assign cluster ids to observations\n",
    "kmeans.fit(train_scaled[cluster_vars])\n",
    "\n",
    "cluster1 = kmeans.predict(train_scaled[cluster_vars])\n",
    "\n",
    "cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled['admission_to_debt_cluster'] = cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(train_scaled['admission_to_debt_cluster'], prefix= 'area', drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the cluster\n",
    "#sns.scatterplot(data=train_scaled['area_cluster'], y = 'longitude', x = 'logerror', hue= 'area_cluster')\n",
    "plt.show()\n",
    "sns.barplot(data=train_scaled, x='admission_to_debt_cluster', y='roi_5yr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
