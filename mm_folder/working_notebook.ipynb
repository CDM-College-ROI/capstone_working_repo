{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook dependencies \n",
    "%matplotlib inline\n",
    "import matplotlib as mlp\n",
    "mlp.rcParams['figure.dpi'] = 300\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# time/sleep modules\n",
    "from time import sleep\n",
    "\n",
    "# random module for sleep combination\n",
    "import random\n",
    "\n",
    "import vaex as vx\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_majors_df():\n",
    "\n",
    "    '''Function to initially pull and merge the two (2) needed \n",
    "    College Scorecard tables for period 2018-2019.'''\n",
    "\n",
    "    # checking if dataset exists\n",
    "    filename = \"majors_table.csv\"\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        \n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        print(f'dataframe shape: {df.shape}')\n",
    "\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "        filename_01 = \"FieldOfStudyData1718_1819_PP.csv\"\n",
    "        filename_02 = \"MERGED2018_19_PP.csv\"\n",
    "        \n",
    "        df_parent = pd.read_csv(filename_01, low_memory=False)\n",
    "        df_child = pd.read_csv(filename_02, low_memory=False)\n",
    "\n",
    "        df_parent[\"UNITID\"] = df_parent[\"UNITID\"].astype(\"Int32\", errors='ignore')\n",
    "        df_child[\"UNITID\"] = df_child[\"UNITID\"].astype(\"Int32\", errors='ignore')\n",
    "\n",
    "        df = df_parent.merge( \n",
    "        df_child,\n",
    "        how = \"left\",\n",
    "        on = \"UNITID\",\n",
    "        copy = False\n",
    "        )\n",
    "        # cache the newly created dataframe as a .csv file\n",
    "        df.to_csv(\"majors_table.csv\")\n",
    "        # print the df shape\n",
    "        print(f'dataframe shape: {df.shape}')\n",
    "\n",
    "        # return the dataframe\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (224849, 121)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNITID</th>\n",
       "      <th>OPEID6</th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CONTROL</th>\n",
       "      <th>MAIN</th>\n",
       "      <th>CIPCODE</th>\n",
       "      <th>CIPDESC</th>\n",
       "      <th>CREDLEV</th>\n",
       "      <th>CREDDESC</th>\n",
       "      <th>IPEDSCOUNT1</th>\n",
       "      <th>...</th>\n",
       "      <th>EARN_COUNT_WNE_3YR</th>\n",
       "      <th>EARN_CNTOVER150_3YR</th>\n",
       "      <th>EARN_COUNT_PELL_NE_3YR</th>\n",
       "      <th>EARN_PELL_NE_MDN_3YR</th>\n",
       "      <th>EARN_COUNT_NOPELL_NE_3YR</th>\n",
       "      <th>EARN_NOPELL_NE_MDN_3YR</th>\n",
       "      <th>EARN_COUNT_MALE_NE_3YR</th>\n",
       "      <th>EARN_MALE_NE_MDN_3YR</th>\n",
       "      <th>EARN_COUNT_NOMALE_NE_3YR</th>\n",
       "      <th>EARN_NOMALE_NE_MDN_3YR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100654.0</td>\n",
       "      <td>1002</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>Agriculture, General.</td>\n",
       "      <td>3</td>\n",
       "      <td>Bachelors Degree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100654.0</td>\n",
       "      <td>1002</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>Animal Sciences.</td>\n",
       "      <td>3</td>\n",
       "      <td>Bachelors Degree</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100654.0</td>\n",
       "      <td>1002</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>Food Science and Technology.</td>\n",
       "      <td>3</td>\n",
       "      <td>Bachelors Degree</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100654.0</td>\n",
       "      <td>1002</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>Food Science and Technology.</td>\n",
       "      <td>5</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100654.0</td>\n",
       "      <td>1002</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>Food Science and Technology.</td>\n",
       "      <td>6</td>\n",
       "      <td>Doctoral Degree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UNITID  OPEID6                    INSTNM CONTROL  MAIN  CIPCODE  \\\n",
       "0  100654.0    1002  Alabama A & M University  Public     1      100   \n",
       "1  100654.0    1002  Alabama A & M University  Public     1      109   \n",
       "2  100654.0    1002  Alabama A & M University  Public     1      110   \n",
       "3  100654.0    1002  Alabama A & M University  Public     1      110   \n",
       "4  100654.0    1002  Alabama A & M University  Public     1      110   \n",
       "\n",
       "                        CIPDESC  CREDLEV          CREDDESC  IPEDSCOUNT1  ...  \\\n",
       "0         Agriculture, General.        3  Bachelors Degree          NaN  ...   \n",
       "1              Animal Sciences.        3  Bachelors Degree          5.0  ...   \n",
       "2  Food Science and Technology.        3  Bachelors Degree          9.0  ...   \n",
       "3  Food Science and Technology.        5   Master's Degree          5.0  ...   \n",
       "4  Food Science and Technology.        6   Doctoral Degree          1.0  ...   \n",
       "\n",
       "   EARN_COUNT_WNE_3YR EARN_CNTOVER150_3YR EARN_COUNT_PELL_NE_3YR  \\\n",
       "0   PrivacySuppressed   PrivacySuppressed      PrivacySuppressed   \n",
       "1   PrivacySuppressed   PrivacySuppressed      PrivacySuppressed   \n",
       "2   PrivacySuppressed   PrivacySuppressed      PrivacySuppressed   \n",
       "3   PrivacySuppressed   PrivacySuppressed      PrivacySuppressed   \n",
       "4   PrivacySuppressed   PrivacySuppressed      PrivacySuppressed   \n",
       "\n",
       "  EARN_PELL_NE_MDN_3YR EARN_COUNT_NOPELL_NE_3YR EARN_NOPELL_NE_MDN_3YR  \\\n",
       "0    PrivacySuppressed        PrivacySuppressed      PrivacySuppressed   \n",
       "1    PrivacySuppressed        PrivacySuppressed      PrivacySuppressed   \n",
       "2    PrivacySuppressed        PrivacySuppressed      PrivacySuppressed   \n",
       "3    PrivacySuppressed        PrivacySuppressed      PrivacySuppressed   \n",
       "4    PrivacySuppressed        PrivacySuppressed      PrivacySuppressed   \n",
       "\n",
       "  EARN_COUNT_MALE_NE_3YR EARN_MALE_NE_MDN_3YR EARN_COUNT_NOMALE_NE_3YR  \\\n",
       "0      PrivacySuppressed    PrivacySuppressed        PrivacySuppressed   \n",
       "1      PrivacySuppressed    PrivacySuppressed        PrivacySuppressed   \n",
       "2      PrivacySuppressed    PrivacySuppressed        PrivacySuppressed   \n",
       "3      PrivacySuppressed    PrivacySuppressed        PrivacySuppressed   \n",
       "4      PrivacySuppressed    PrivacySuppressed        PrivacySuppressed   \n",
       "\n",
       "  EARN_NOMALE_NE_MDN_3YR  \n",
       "0      PrivacySuppressed  \n",
       "1      PrivacySuppressed  \n",
       "2      PrivacySuppressed  \n",
       "3      PrivacySuppressed  \n",
       "4      PrivacySuppressed  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing parent table\n",
    "\n",
    "df_parent = pd.read_csv(\"/Users/mijailmariano/codeup-data-science/capstone_working_repo/mm_folder/FieldOfStudyData1718_1819_PP.csv\")\n",
    "print(f'df shape: {df_parent.shape}')\n",
    "df_parent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing df_parent unitid type to int64\n",
    "\n",
    "# df_parent[\"UNITID\"] = df_parent[\"UNITID\"].astype(\"Int64\")\n",
    "\n",
    "# df_parent[\"UNITID\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check conversion worked\n",
    "\n",
    "# df_parent.head() # checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the child table\n",
    "\n",
    "# df_child = pd.read_csv(\"/Users/mijailmariano/codeup-data-science/capstone_working_repo/mijail_folder/MERGED2018_19_PP.csv\", low_memory=False)\n",
    "# print(f'df shape: {df_child.shape}')\n",
    "# df_child.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info\n",
    "# df_child[\"UNITID\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_child[\"UNITID\"] = df_child[\"UNITID\"].astype(\"Int64\", errors=\"ignore\")\n",
    "# df_child[\"UNITID\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check conversion works\n",
    "\n",
    "# df_child.head() # looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the two tables together\n",
    "\n",
    "'''DataFrame.merge(\n",
    "    right, \n",
    "    how='inner', \n",
    "    on=None, \n",
    "    left_on=None, \n",
    "    right_on=None, \n",
    "    left_index=False, \n",
    "    right_index=False, \n",
    "    sort=False, \n",
    "    suffixes=('_x', '_y'), \n",
    "    copy=True, \n",
    "    indicator=False, \n",
    "    validate=None)'''\n",
    "\n",
    "# df = df_parent.merge( \n",
    "#     df_child,\n",
    "#     how = \"left\",\n",
    "#     on = \"UNITID\",\n",
    "#     copy = False\n",
    "# )\n",
    "\n",
    "# parent table contains Null Values in \"UNITID\"\n",
    "# there should be ~225K records returned and ~3Kish features returned\n",
    "\n",
    "# print(f'dataframe shape: {df.shape}')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe shape: (224849, 3109)\n",
    "\n",
    "# df[\"UNITID\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to merge initial majors tables\n",
    "\n",
    "# def get_mass_majors_df():\n",
    "\n",
    "#     '''Function to initially pull and merge the two (2) needed \n",
    "#     College Scorecard tables for period 2018-2019.'''\n",
    "\n",
    "#     # checking if dataset exists\n",
    "#     filename = \"majors_table.csv\"\n",
    "    \n",
    "#     if os.path.isfile(filename):\n",
    "        \n",
    "#         df = pd.read_csv(filename)\n",
    "\n",
    "#         print(f'dataframe shape: {df.shape}')\n",
    "\n",
    "#         return df\n",
    "\n",
    "#     else:\n",
    "#         filename_01 = \"FieldOfStudyData1718_1819_PP.csv\"\n",
    "#         filename_02 = \"MERGED2018_19_PP.csv\"\n",
    "        \n",
    "#         df_parent = pd.read_csv(filename_01, low_memory=False)\n",
    "#         df_child = pd.read_csv(filename_02, low_memory=False)\n",
    "\n",
    "#         df_parent[\"UNITID\"] = df_parent[\"UNITID\"].astype(\"Int32\", errors='ignore')\n",
    "#         df_child[\"UNITID\"] = df_child[\"UNITID\"].astype(\"Int32\", errors='ignore')\n",
    "\n",
    "#         df = df_parent.merge( \n",
    "#         df_child,\n",
    "#         how = \"left\",\n",
    "#         on = \"UNITID\",\n",
    "#         copy = False\n",
    "#         )\n",
    "#         # cache the newly created dataframe as a .csv file\n",
    "#         df.to_csv(\"majors_table.csv\")\n",
    "#         # print the df shape\n",
    "#         print(f'dataframe shape: {df.shape}')\n",
    "\n",
    "#         # return the dataframe\n",
    "#         return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_mass_majors_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vx = vx.from_csv(\n",
    "#     \"majors_table.csv\", \n",
    "#     convert = True)\n",
    "\n",
    "# (df_vx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### ``compression functions and potential approaches``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "def save_compressed_df(df, dirPath, fileName):\n",
    "    \n",
    "    \"\"\"Save a Pandas dataframe as a zipped .csv file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.core.frame.DataFrame\n",
    "    Input dataframe.\n",
    "\n",
    "    dirPath: str or pathlib.PosixPath\n",
    "    Parent directory of the zipped file.\n",
    "\n",
    "    fileName: str\n",
    "    File name without extension.\n",
    "    \"\"\"\n",
    "\n",
    "    dirPath = Path(dirPath)\n",
    "\n",
    "    path_zip = dirPath / f'{fileName}.csv.zip'\n",
    "\n",
    "    txt = df.to_csv(index=False)\n",
    "\n",
    "    with zipfile.ZipFile(path_zip, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "\n",
    "        zf.writestr(f'{fileName}.csv', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate and write to file method?\n",
    "# testing out the function\n",
    "\n",
    "path = \"/Users/mijailmariano/codeup-data-science/capstone_working_repo/\"\n",
    "\n",
    "save_compressed_df(df, path, \"majors_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "\n",
    "    \"\"\" Iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "\n",
    "            c_min = df[col].min()\n",
    "\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "\n",
    "            else:\n",
    "                \n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reduce_mem_usage(df)\n",
    "print(f'df shape {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAEX library\n",
    "import vaex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gzip method?\n",
    "\n",
    "df.to_csv(\"/tmp/df.csv.gz\", compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
