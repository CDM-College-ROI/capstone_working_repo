{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook dependencies \n",
    "%matplotlib inline\n",
    "import matplotlib as mlp\n",
    "mlp.rcParams['figure.dpi'] = 300\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# time/sleep modules\n",
    "from time import sleep\n",
    "\n",
    "# random module for sleep combination\n",
    "import random\n",
    "\n",
    "import vaex as vx\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing parent table\n",
    "\n",
    "df_parent = pd.read_csv(\"/Users/mijailmariano/codeup-data-science/capstone_working_repo/mijail_folder/FieldOfStudyData1718_1819_PP.csv\")\n",
    "print(f'df shape: {df_parent.shape}')\n",
    "df_parent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing df_parent unitid type to int64\n",
    "\n",
    "df_parent[\"UNITID\"] = df_parent[\"UNITID\"].astype(\"Int64\")\n",
    "\n",
    "df_parent[\"UNITID\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check conversion worked\n",
    "\n",
    "df_parent.head() # checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the child table\n",
    "\n",
    "df_child = pd.read_csv(\"/Users/mijailmariano/codeup-data-science/capstone_working_repo/mijail_folder/MERGED2018_19_PP.csv\", low_memory=False)\n",
    "print(f'df shape: {df_child.shape}')\n",
    "df_child.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info\n",
    "df_child[\"UNITID\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_child[\"UNITID\"] = df_child[\"UNITID\"].astype(\"Int64\", errors=\"ignore\")\n",
    "df_child[\"UNITID\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check conversion works\n",
    "\n",
    "df_child.head() # looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the two tables together\n",
    "\n",
    "'''DataFrame.merge(\n",
    "    right, \n",
    "    how='inner', \n",
    "    on=None, \n",
    "    left_on=None, \n",
    "    right_on=None, \n",
    "    left_index=False, \n",
    "    right_index=False, \n",
    "    sort=False, \n",
    "    suffixes=('_x', '_y'), \n",
    "    copy=True, \n",
    "    indicator=False, \n",
    "    validate=None)'''\n",
    "\n",
    "df = df_parent.merge( \n",
    "    df_child,\n",
    "    how = \"left\",\n",
    "    on = \"UNITID\",\n",
    "    copy = False\n",
    ")\n",
    "\n",
    "# parent table contains Null Values in \"UNITID\"\n",
    "# there should be ~225K records returned and ~3Kish features returned\n",
    "\n",
    "print(f'dataframe shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe shape: (224849, 3109)\n",
    "\n",
    "df[\"UNITID\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to merge initial majors tables\n",
    "\n",
    "def get_mass_majors_df():\n",
    "\n",
    "    '''Function to initially pull and merge the two (2) needed \n",
    "    College Scorecard tables for period 2018-2019.'''\n",
    "\n",
    "    # checking if dataset exists\n",
    "    filename = \"majors_table.csv\"\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        \n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        print(f'dataframe shape: {df.shape}')\n",
    "\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "        filename_01 = \"FieldOfStudyData1718_1819_PP.csv\"\n",
    "        filename_02 = \"MERGED2018_19_PP.csv\"\n",
    "        \n",
    "        df_parent = pd.read_csv(filename_01, low_memory=False)\n",
    "        df_child = pd.read_csv(filename_02, low_memory=False)\n",
    "\n",
    "        df_parent[\"UNITID\"] = df_parent[\"UNITID\"].astype(\"Int32\", errors='ignore')\n",
    "        df_child[\"UNITID\"] = df_child[\"UNITID\"].astype(\"Int32\", errors='ignore')\n",
    "\n",
    "        df = df_parent.merge( \n",
    "        df_child,\n",
    "        how = \"left\",\n",
    "        on = \"UNITID\",\n",
    "        copy = False\n",
    "        )\n",
    "        # cache the newly created dataframe as a .csv file\n",
    "        df.to_csv(\"majors_table.csv\")\n",
    "        # print the df shape\n",
    "        print(f'dataframe shape: {df.shape}')\n",
    "\n",
    "        # return the dataframe\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_mass_majors_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vx = vx.from_csv(\n",
    "    \"majors_table.csv\", \n",
    "    convert = True)\n",
    "\n",
    "(df_vx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### ``compression functions and potential approaches``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "def save_compressed_df(df, dirPath, fileName):\n",
    "    \n",
    "    \"\"\"Save a Pandas dataframe as a zipped .csv file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.core.frame.DataFrame\n",
    "    Input dataframe.\n",
    "\n",
    "    dirPath: str or pathlib.PosixPath\n",
    "    Parent directory of the zipped file.\n",
    "\n",
    "    fileName: str\n",
    "    File name without extension.\n",
    "    \"\"\"\n",
    "\n",
    "    dirPath = Path(dirPath)\n",
    "\n",
    "    path_zip = dirPath / f'{fileName}.csv.zip'\n",
    "\n",
    "    txt = df.to_csv(index=False)\n",
    "\n",
    "    with zipfile.ZipFile(path_zip, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "\n",
    "        zf.writestr(f'{fileName}.csv', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate and write to file method?\n",
    "# testing out the function\n",
    "\n",
    "path = \"/Users/mijailmariano/codeup-data-science/capstone_working_repo/\"\n",
    "\n",
    "save_compressed_df(df, path, \"majors_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "\n",
    "    \"\"\" Iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "\n",
    "            c_min = df[col].min()\n",
    "\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "\n",
    "            else:\n",
    "                \n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reduce_mem_usage(df)\n",
    "print(f'df shape {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAEX library\n",
    "import vaex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gzip method?\n",
    "\n",
    "df.to_csv(\"/tmp/df.csv.gz\", compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
